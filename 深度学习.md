# 深度学习

## 1 回归与分类

### 1.1 Logistic 回归

1. 定义

   目标：给定数据点 $X^{(n)}∈R^m$ 和相应标签 $t^{(n)}∈Ω$ ，找到一个映射 $f:R^m→Ω$

   - 回归的目的是预测一个<font color='blue'>连续的数值变量</font>，如果Ω是一个<font color='blue'>连续</font>的集合称其为<font color='red'>回归(regression)</font>
   - 分类的目的是将数据<font color='blue'>划分为离散的类</font>，如果Ω是一个<font color='blue'>离散</font>的集合称其为<font color='red'>分类(classification)</font>

2. 回归类型

   - 线性回归：用于建立因变量和自变量之间线性关系的统计方法
     $$
     f(x) =w x + \beta
     $$
     其中，$y$是因变量，$x_1, x_2, \cdots, x_n$是自变量，$\beta_0, \beta_1, \cdots, \beta_n$是回归系数。

   - 多项式回归：多项式回归是一种扩展了线性回归的方法，它可以拟合因变量和自变量之间的非线性关系。
     $$
     f(x) = \beta + w_1 x + w_2 x^2 + w_3 x^3 + \cdots + w_m x^m
     $$
     其中，$m$是多项式的最高次数。

   通过均方误差 （$MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$）进行训练，得到最终的 $f(x)$。

3. 分类方法

   - 线性回归分类：感知机、SVM

   - 非线性回归分类：<font color='red'>sigmoid function</font>
     $$
     f(x) = \frac{1}{1+e^{-x}}
     $$
     ![image-20240124165916191](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240124165916191.png)

   - 伯努利分布假设
     $$
     P(x)=\begin{cases}p,x=1\\
     	1-p,x=0
     \end{cases}
     $$
     

4. Logistic 回归

   <font color='blue'>Logistic 回归</font>是一种用于<font color='red'>二分类问题</font>的模型，它可以预测一个离散输出，例如0或1。

   - **Logistic回归函数**

     对于<font color='blue'>二分类问题</font>，一个0-1单元足以表示一个<font color='red'>标签</font>
     $$
     P(t=1|x)=\frac{1}{1+e^{-θ^\top x}}\triangleq h(x)
     $$
     其中$x$是输入，$t$ 是标签，$θ$ 是参数。我们的目标是寻找一个$θ$值使得概率$P(t=1|x)=h(x)$​。

     我们实质上是在<font color='blue'>用另一个连续函数来“回归”一个离散的函数</font>(x→t）

   - **最大化条件数据似然**

     最大化条件数据似然是一种参数估计方法，它利用已知的数据和条件分布，找到最有可能（即最大概率）导致这种分布的参数值。

     将t看作一个<font color='red'>伯努利变量</font>，并且$P(t=1|x)=h(x;\theta)$​。条件似然函数为
     $$
     P(t^{(1)},...,t^{(n)}|X;\theta)=\prod_{n=1}^{N}h(x^{(n)})^{t^{(n)}}(1-h(x^{(n)})^{1-t^{(n)}}
     $$
     <font color='red'>最大化似然等</font>同于最小化下式：
     $$
     E(θ)=-\frac{1}{n}lnP(t^{(1)},...,t^{(n)})=-\frac{1}{n}\sum^{n}_{n=1}\left(t^{(n)}ln\ h(x^{(n)}+(1-t^{(n)})ln\ (1-h(x^{(n)})\right)
     $$

   - **交叉熵误差函数**

     对于带有二元标签的一组训练样本$\{(x^{(n)},t^{(n)}):n=1,...,N\}$，定义<font color='red'>交叉熵误差（cross-entropyerror）函数</font>
     $$
     E(θ)=-\frac{1}{n}lnP(t^{(1)},...,t^{(n)})=-\frac{1}{n}\sum^{n}_{n=1}\left(t^{(n)}ln\ h(x^{(n)}+(1-t^{(n)})ln\ (1-h(x^{(n)})\right)
     $$

5. 训练和测试

   - 计算梯度
     $$
     \nabla E(\theta)=\frac{1}{N}\sum_Nx^{(n)}(h(x^{(n)})-t^{(n)})
     $$

   - 一些正则化项添加到成本函数中
     $$
     J(\theta)=E(\theta)+\lambda|\theta|^2/2
     $$

   - <font color='blue'>训练</font>：学习θ来最小化成本函数，其中$\alpha$是学习率。
     $$
     \theta \leftarrow \theta-\alpha \nabla J(\theta)
     $$

   - <font color='blue'>测试</font>：对于新的输入$x$，如果$P(t=1|x)>P(t=0|x)$，则可以预测输入为类别1，否则就是类别0。

### 1.2 Softmax 回归

1. 类别标签的表示

   **<font color='red'>one-hot编码</font>**(1-of-K)：将离散的类别标签转换为向量形式，其中每个类别都由一个唯一的二进制值表示。

   对于一个具有 $K$ 个可能类别的问题，1-of-K 表示法将每个类别映射为一个长度为 $K$ 的二进制向量，其中只有一个元素为1，其余为0。被设置为1的位置对应于类别的索引。

   > 例如，对于一个三类分类问题（$K = 3$），类别A、B和C可能被表示为：
   >
   > - 类别A：$1, 0, 0$
   > - 类别B：$0, 1, 0$
   > - 类别C：$0, 0, 1$

   - **唯一性：** 每个类别的表示是唯一的，因为只有一个元素为1。
   - **独立性：** 每个类别的表示与其他类别的表示是相互独立的，不存在冗余信息。

2. 分布假设
   - 正态分布假设

     **正态分布假**设是指假设数据集服从正态分布的概率分布。
     $$
     f(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)
     $$
     其中，$\mu$ 是均值（分布的中心），$\sigma$ 是标准差（度量分布的离散程度）。

   - Multinoulli分布假设

     **Multinoulli分布假设**描述了离散型随机变量的概率分布，特别适用于多类别分类问题。

     对于一个给定的样本，其类别的概率分布可以由参数 $\phi_k$ 来表示。对于一个离散型随机变量 $X$ 表示类别的取值，其概率质量函数如下：
     $$
     P(X=k) = \phi_k
     $$
     这表示样本属于类别 $k$ 的概率为 $\phi_k$ 。

3. Softmax 函数

   Softmax回归，也称为多类逻辑回归或多类交叉熵分类，是一种用于多类别分类的模型。

   假设有 $K$ 个类别，对于输入特征向量$x$​ ，Softmax回归的模型表达式如下：
   $$
   P(y=k \mid x) = \frac{e^{w_k \cdot x + b_k}}{\sum_{j=1}^{K} e^{w_j \cdot x + b_j}}
   $$
   其中，$P(y=k \mid x)$ 是给定输入 $x$ 属于类别 $k$ 的概率。$ w_k $ 和 $ b_k $ 是模型的参数，分别表示第 $k$个类别的权重和偏置。

4. 最大条件似然

   最大条件似然的目标是找到一组参数，使得在给定输入 $x$ 的条件下，观察到实际类别 $y$ 的概率最大。Softmax 回归的最大条件似然目标函数为：
   $$
   P(t^{(1)},...,t^{(N)}|X)=\prod_{n=1}^N\prod_{k=1}^KP(t_k^{(n)}=1|x^{(n)})^{t_k^{(n)}}
   $$
   其中：

   - $N$ 是样本数量。
   - $t_k^{(n)}$ 是one-hot函数，当 $t_k$ 等于 $k$ 时为1，否则为0。

5. 交叉摘误差函数

   Softmax回归通常使用交叉熵损失函数来衡量模型预测与实际类别之间的差异。对于 $N$​ 个样本，交叉熵损失函数的表达式为：
   $$
   J(w, b) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} t_k^{(n)} \ln P(t_k^{(n)}=1|x^{(n)})
   $$
   其中：

   - $J(w, b) $ 是损失函数。
   - $ t_k^{(n)} $ 是样本$n$ 属于类别 $k$ 的实际标签（1或0）。

   - $P(t_k^{(n)}=1|x^{(n)})$ 是模型对样本 $i$ 属于类别 $k$ 的预测概率。

6. 计算梯度

   Softmax 回归的梯度计算涉及对损失函数关于模型参数的偏导数。
   $$
   \frac{\part E^{(n)}}{\part \theta^{(k)}}=\delta_k^{(n)}x^{(n)}\\
   \delta_k^{(n)}=\frac{\part E^{(n)}}{\part u^{(k)}}=-(t_k^{(n)}-h_k^{(n)})
   $$
   上式是局部敏感度或局部梯度。

7. 训练和测试

   - 训练：训练Softmax回归的过程通常涉及使用<font color='blue'>梯度下降</font>或其变种来<font color='blue'>最小化交叉熵损失</font>。梯度下降的步骤包括计算损失函数对参数的梯度，然后更新参数以减小损失。

   $$
   \theta ← \theta -\alpha \nabla J(\theta)
	$$
- 测试：在个类别中找出 $P(k=1|x$) 最大的类别，作为新输入 $x$ 的预测标签

**总结**

![image-20240124180021695](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240124180021695.png)

### 1.3 **案例1：Softmax实现手写数字识别**

**相关知识点: numpy科学计算包，如向量化操作，广播机制等**

**1 简介**

本次案例中，你需要用python实现Softmax回归方法，用于MNIST手写数字数据集分类任务。你需要完成前向计算loss和参数更新。

你需要首先实现Softmax函数和交叉熵损失函数的计算。
$$
y=softmax(W^Tx+b)\\
L=CrossEntropy(y,label)
$$
在更新参数的过程中，你需要实现参数梯度的计算，并按照随机梯度下降法来更新参数。
$$
\frac{\partial L}{\partial W},\frac{\partial L}{\partial b}
$$
  具体计算方法可自行推导，或参照第三章课件。

 


**2 MNIST数据集**

 MNIST手写数字数据集是机器学习领域中广泛使用的图像分类数据集。它包含60,000个训练样本和10,000个测试样本。这些数字已进行尺寸规格化，并在固定尺寸的图像中居中。每个样本都是一个784×1的矩阵，是从原始的28×28灰度图像转换而来的。MNIST中的数字范围是0到9。下面显示了一些示例。 注意：在训练期间，切勿以任何形式使用有关测试样本的信息。

![image.png](https://raw.githubusercontent.com/ZzDarker/figure/main/img/13f138b5-4ccb-435d-a956-d3ffa3e6a6c0.png)

**3 任务要求**

1. **代码清单**

a) data/ 文件夹：存放MNIST数据集。你需要下载数据，解压后存放于该文件夹下。下载链接见文末，解压后的数据为 *ubyte 形式；

b) solver.py 这个文件中实现了训练和测试的流程。建议从这个文件开始阅读代码；

c) dataloader.py 实现了数据加载器，可用于准备数据以进行训练和测试；

d) visualize.py 实现了plot_loss_and_acc函数，该函数可用于绘制损失和准确率曲线；

e) optimizer.py 你需要实现带momentum的SGD优化器，可用于执行参数更新；

f) loss.py 你需要实现softmax_cross_entropy_loss，包含loss的计算和梯度计算；

g) runner.ipynb 完成所有代码后的执行文件，执行训练和测试过程。

 

**2.** **要求**

 我们提供了完整的代码框架，你只需要完成**optimizer.py，loss.py** 中的 **#TODO**部分。你需要提交整个代码文件和带有结果的**runner.ipynb (****不要提交数据集****)** 并且附一个**pdf**格式报告，内容包括：

a) 记录训练和测试的准确率。画出训练损失和准确率曲线；

b) 比较使用和不使用momentum结果的不同，可以从训练时间，收敛性和准确率等方面讨论差异；

c) 调整其他超参数，如学习率，Batchsize等，观察这些超参数如何影响分类性能。写下观察结果并将这些新结果记录在报告中。

 

**4** **其他**

1. 注意代码的执行效率，尽量不要使用for循环；
2. 不要在**pdf**报告中粘贴很多代码(只能包含关键代码)，对添加的代码作出解释;
3. 不要使用任何深度学习框架，如TensorFlow，Pytorch等；
4. 禁止抄袭。

 

**5** **参考**

1. 数据集下载：[http://yann.lecun.com/exdb/mnist/index.html](http://yann.lecun.com/exdb/mnist/)

## 2 多层感知机

### 2.1 前向计算

1. 多层感知机（Multi-layer Perceptron，MLP）

   ![image-20240129225229441](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240129225229441.png)

   - 除了输入共L层
   - 连接类型：
     - 相邻层之间的神经元两两连接
     - 相邻层之间没有反馈连接
     - 同一层内没有横向连接
   - 每个神经元接收前一层神经元的输出，并根据激活函数作出响应

2. 前向传播

   - $l=1,...,L-1$层

     $l$ 层的神经元 $j$ 的<font color='blue'>输入</font>：$u_j^{(l)}=\sum_jw_{ji}^{(l)}y_i^{(l-1)}+b_j^{(l)}$，注意$y^{(0)}=x$

     $l$ 层的神经元 $j$ 的<font color='blue'>输出</font>：$y_j^{(l)}=f(u_j^{(l)})$；$f(·)$是激活函数

   - $l=L$层：对应任务层（$Softmax$​分类、回归、图像去噪）

3. 激活函数

   <img src="https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240129230216709.png" alt="image-20240129230216709" style="zoom:50%;" />

   - Sigmoid函数
     $$
     f(z)=\frac{1}{1+e^{-z}}
     $$
     梯度：$f^\prime (z)=f(z)(1-f(z))$
   
   - 双曲正切函数
     $$
     f(z)=tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}
     $$
     
   
     梯度：$f^\prime (z)=1-f(z)^2$
   
      - 整流线性激活函数（ReLU）
        $$
        f(z)=max(0,z)
        $$
        梯度：$f^\prime (z)=\begin{cases}1,if\ z≥0\\0,else\end{cases}$

4. 向量形式的前向计算

   如果前一层有N个神经元，当前层有M个神经元，则定义参数矩阵和偏置向量如下：
   $$
   W^{(l)}=\begin{pmatrix}
       W_{11} & \cdots & w_{1N} \\
       \vdots & \vdots & \vdots \\
       W_{M1} & \cdots & w_{MN} \\
   \end{pmatrix},
   b^{(l)}=\begin{pmatrix}
       b_1 \\
       \vdots  \\
       b_M &  \\
   \end{pmatrix}
   $$
   对于$l=1,...,L-1$
   $$
   u^{(l)}=W{(l)}y{(l-1)}+b{(l)}and\ y{(l)}=f(u^{(l)})
   $$

### 2.3 反向传播

1. 损失函数
   $$
   E=\frac{1}{N}\sum_{n=1}^NE^{(n)}
   $$
   其中$E^{(n)}$是每个样本$n$的损失函数。

   - 均方误差
     $$
     E^{(n)}=\frac{1}{2}\sum_{k=1}^K(t_k-y_k^{L})^2,y_k^{(L)}=\frac{1}{1+e^{-z}},z=w_k^{(L)\top}y^{(L-1)}+b_k^{L}
     $$

   - 交叉熵误差
     $$
     E^{(n)}=-\sum_{k=1}^Kt_kln\ y_k^{(L)},y_k^{(L)}=\frac{e^{z_k}}{\sum_{j=1}^Ke^{z_j}},z_k=w_k^{(L)\top}y^{(L-1)}+b_k^{L}
     $$
     其中t是目标向量

2. 参数更新

   - 更新参数$w_{ji}^{(l)}$和$b_j$
     $$
     w_{ji}^{(l)}=w_{ji}^{(l)}-\alpha \frac{\partial E}{\partial w_{ji}^{(l)}}\\b_j^{(l)}=b_j^{(l)}-\alpha \frac{\partial E}{\partial b_j^{(l)}}
     $$

   - <font color='blue'>参数衰减</font>：通常作用于$w_{ji}^{(l)}$，相当于在损失函数加上额外一项：
     $$
     J=E+\frac{\lambda }{2}\sum_{i,j,l}(w_{ji}^{(l)})^2
     $$
     $w$的参数更新为：
     $$
     w_{ji}^{(l)}=w_{ji}^{(l)}-\alpha \frac{\partial E}{\partial w_{ji}^{(l)}}-\alpha \lambda w_{ji}^{(l)}
     $$

3. 梯度(Gradient)、局部敏感度(local sensitivity）

   - 局部敏感度
     $$
     \delta_i^{(l)}=\frac {\part E^{(n)}}{\part u_i^{(l)}}
     $$

   - 计算<font color='red'>梯度</font>等价于计算<font color='red'>各层的局部敏感度</font>
     $$
     \frac {\part E^{(n)}}{\part w_{ji}^{(l)}}=\delta_i^{(l)}\frac {\part u_j^{(l)}}{\part w_{ji}^{(l)}}=\delta_i^{(l)}f(u_i^{(l-1)})\\\frac {\part E^{(n)}}{\part b_j^{(l)}}=\delta_i^{(l)}
     $$

   - 多层感知机<font color='blue'>最后一层</font>的输出：
     $$
     y_k^{L}=f(u_k^{(L)})=f(w_k^{(L)\top}y^{(L-1)}+b_k^{(L)})
     $$
     $f$ 可以是 logistic sigmoid、tanh、ReLU

   - 其它层的局部敏感度
     $$
     \delta_i^{(l)}=\frac {\part E^{(n)}}{\part u_i^{(l)}}=\sum_j\delta_j^{(l+1)}w_{ji}^{(l+1)}f^\prime(u_i^{(l)})
     $$
     已知$l+1$层的$\delta$，可求$l$ 层的 $\delta$ 。因此可以在反向传播中计算$\delta_i^{(l)},\part E/\part W^{(l)},\part E/\part b^{(l)}$,以$l=L,L－1,…,1$的顺序

4. 向量形式的反向传播

   - 局部敏感度
     $$
     \delta_i^{(l)}=\left(\frac {\part E^{(n)}}{\part u_1^{(l)}},\frac {\part E^{(n)}}{\part u_2^{(l)}},...\right)
     $$

   - 对于<font color='blue'>输出层</font>$L$

     均方损失：$\delta^{(L)}=(y^{(L)}-t)\bigodot f^\prime (u^{(L)})$，其中$\bigodot$表示逐元素相乘。

     交叉熵损失：$\delta^{(L)}=y^{(L)}-t$

   - 对于<font color='blue'>隐含层</font>$1≤l＜L$
     $$
     \delta^{(l)}=(W^{(l+1)})^\top \delta^{(l+1)}\bigodot f^\prime (u^{(L)})
     $$

   - 计算<font color='blue'>梯度</font>$1≤l≤L$
     $$
     \frac {\part E^{(n)}}{\part W^{(l)}}=\delta^{(l)}f(u^{(l-1)}),\frac {\part E^{(n)}}{\part b^{(l)}}=\delta^{(l)}
     $$

   - 更新参数
     $$
     W^{(l)}=W^{(l)}-\frac{\alpha}{N}\sum_n \frac{\partial E}{\partial W^{(l)}}-\alpha \lambda W^{(l)},b^{(l)}=b^{(l)}-\frac{\alpha}{N}\sum_n \frac{\partial E}{\partial b^{(l)}}
     $$

5. <font color='blue'>梯度消失</font>(Gradient Vanishing)

   对于logistic、tanh这两个激活函数，从第L层到第一层，$\delta^{(l)}$变得越来越小。
   <font color='red'>浅层的梯度会逐渐接近于零</font>，<font color='blue'>RELU</font>可以缓解这个问题。

6. 多层感知机实现

   - 前向计算

     计算$f(u^l)$和$f^\prime (u^l)$，对所有的$l=1,2,…,L$

   - 后向计算

     计算$\delta ^{(l)}$和$\part E/\part W^{(l)},\part E/\part b^{(l)}$对所有的$l=L,L-1,...,1$

   - 更新参数

     对所有$1=1,2…,L,$更新$W^{(l)}$和$b^{(l)}$

   - 模块化编程

     - 用类来实现层，并提供前向和后向计算函数
     - 不同类型的层拥有不同的前向和后向计算函数，例如输入层、隐含层、softmax输出层、sigmoid输出层等
     - 通过组合不同的模块来构造不同的多层感知机模型

### 2.4 层分解

1. 灵活的层分解

   - 输入层或隐含层
     - 全连接层
     - 激活层
   - 平方损失函数层
     - 激活层
     - 损失层
   - 交叉损失层
     - Softmax层+损失层？不必要，因为激活层只能是Softmax层

2. 层分解举例

   - 带隐含层的多层感知机，使用平方误差损失

     ![image-20240130153908897](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240130153908897.png)



### 2.5 训练技巧-1

1. 参数初始化

   W可以从某个分布中采样：

   - 高斯分布(Gaussian)
     均值为零，标准差固定(例如0.01)的高斯分布
   - Xavier
     均值为零，标准差固定为$1/\sqrt{n_{in}}$的一种分布,其中$n_{in}$是当前神经元输入的个数
     通常使用高斯分布或均匀分布
   - MSRA
     均值为零，标准差固定为$2/\sqrt{n_{in}}$的高斯分布

2. 学习率

   随机梯度下降中的学习率α通常远小于批量梯度下降中的，因为更新过程中存在更大的方差。

   - 选择一个<font color='blue'>足够小的学习率</font>使得网络开始<font color='blue'>稳定收敛</font>，在<font color='blue'>收敛速度变慢后将学习率减半</font>。
   - 每一轮训练后都在一组留出数据集(held out set)上<font color='blue'>评估模型</font>，如果相邻两轮训练中目标函数的改变量<font color='blue'>小于某个國值，则减小学习率</font>。
   - 在第t次迭代(iteration)中将学习率修改为$\frac{a}{b+t}$，其中a为初始学习率，b控制学习率何时开始衰减。

3. 训练样本的顺序

   - 如果样本的训练顺序固定，梯度的计算可能会有偏差，并导致收敛情况变差
   - 通常在每轮训练前都要随机打乱(random shuffle)数据集

4. 动量（Momentum）

   动量(Momentum)是一种迫使目标函数沿着“沟壑”快速下降的方法。

   ![image-20240130155030947](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240130155030947.png)
   $$
   v=γv-α\nabla_\theta J(\theta;x^{(i)},t^{(i)})\\\theta=\theta+v
   $$

   - $v$是当前的速度向量
   - $γ∈(0,1]$决定了之前迭代的梯度以多大程度参与到当前的更新中。
   - 一种策略：$γ$设为0.5直到收敛开始稳定，然后增大到0.9或更大。



## 3 卷积神经网络



## 4 深度学习训练技巧

### 4.1 优化器

1. 随机梯度下降及动量

   - <font color='red'>随机梯度下降算法</font>对每批数据 $(X^{(i)},t^{(i)})$ 进行优化
     $$
     g=\nabla_\theta J(\theta;x^{(i)},t^{(i)})\\
     \theta = \theta -\eta g
     $$
     随机梯度下降算法的基本思想是，在每次迭代中，随机选择一个样本 $i$，计算该样本的梯度 $g=\nabla_\theta J(\theta;x^{(i)},t^{(i)})$，然后按照梯度的反方向更新参数 $\theta$，即 $\theta = \theta -\eta g$，其中 $\eta$ 是学习率，控制更新的步长。

   - 基于<font color='red'>动量</font>的更新过程

     为了改善随机梯度下降算法的收敛性，可以引入动量（momentum）的概念，即在更新参数时，考虑之前的更新方向和幅度，使得参数沿着一个平滑的轨迹移动。
     $$
     v=\gamma v-\eta g\\
     \theta =\theta+v
     $$
     其中 $v$ 是动量变量，初始为零向量，$\gamma$ 是动量系数，控制之前更新的影响程度，一般取 $0.9$ 左右的值。

2. Adagrad

   Adagrad 是一种<font color='red'>自适应学习率</font>的梯度下降算法，它可以根据不同的参数调整不同的学习率，使得目标函数更快地收敛。

   - 梯度记为 $g=\nabla_\theta J(\theta;x^{(i)},t^{(i)})$

   - 更新过程

     对于每个参数 $\theta_i$，维护一个累积变量 $c_i$，初始为 0，然后每次将该参数的梯度平方 $g_i^2$ 累加到 $c_i$ 上，即 $c_i=c_i+g_i^2$。
     $$
     c_i=c_i+g_i^2\\
     \theta_i=\theta_i-\frac{\eta}{\sqrt{c_i+\epsilon}}g_i
     $$
     在更新该参数时，使用一个自适应的学习率 $\frac{\eta}{\sqrt{c_i+\epsilon}}$，其中 $\eta$ 是全局学习率，$\epsilon$ 是一个小常数，用于防止除零错误。

   - 工作原理

     如果一个参数的梯度一直很大，那么它的 $c_i$ 也会很大，从而降低它的学习率，防止过度更新；

     如果一个参数的梯度一直很小，那么它的 $c_i$ 也会很小，从而增加它的学习率，加快更新速度。这就实现了自适应的学习率调整，有利于加速收敛和避免震荡。

   - 优点

     计算简单，不需要手动调整学习率，适合处理稀疏数据和特征。

   - 缺点

     累积变量 $c_i$ 会随着迭代次数增加而<font color='red'>不断增大</font>，导致学习率过小，甚至接近于零，使得后期训练缓慢或停滞。

3. RMSProp

   RMSProp算法在Adagrad的基础上提出改进，以解决学习率单调下降的问题

   - 基本思想

     引入一个<font color='red'>遗忘因子</font> $\gamma$ 。对于每个参数 $\theta$，维护一个累积变量 $c$，初始为 0，然后每次将该参数的梯度平方 $g^2$ 乘以一个衰减系数 $(1-\gamma)$，再加到 $c$ 上，即 $c=\gamma c+(1-\gamma)g^2$。
     $$
     c=\gamma c+(1-\gamma)g^2\\
     \theta=\theta-\frac{\eta}{\sqrt{c+\epsilon}}g
     $$
     $\gamma$ 是一个介于 0 和 1 之间的常数，通常为0.9、0.99、0.999，用于控制历史信息的影响程度。

   - 与Adagrad对比

     $c$ 不会随着迭代次数增加而无限增大，而是保持在一个合理的范围内，从而使得学习率下降得更加平稳。

4. Adam

   Adam 算法是一种自适应学习率的梯度下降算法，它结合了 Momentum 和 RMSProp 的优点

   - 简单形式
     $$
     m=\beta_1m+(1-\beta_1)g & \text {(积攒历史梯度)} \\
     c=\beta_2c+(1-\beta_2)g^2 & \text {(积攒历史梯度的平方)} \\
     \theta=\theta-\frac{\eta}{\sqrt{c+\epsilon}}m
     $$
     其中 $\beta_1$ 和 $\beta_2$ 是两个介于 0 和 1 之间的常数，用于控制历史信息的影响程度。一般取 $\beta_1=0.9$ 和 $\beta_2=0.999$，$\epsilon=10^{-8}$。

   - 完整形式
     $$
     m=\beta_1m+(1-\beta_1)g\ ,m_t=\frac{m}{1-\beta_1^t} \\
     c=\beta_2c+(1-\beta_2)g^2\ ,c_t=\frac{c}{1-\beta_2^t} \\
     \theta=\theta-\frac{\eta}{\sqrt{c_t+\epsilon}}m_t
     $$
     为了消除偏差，还需要对 $m$ 和 $c$ 进行偏差修正，即除以 $1-\beta_1^t$ 和 $1-\beta_2^t$，其中 $t$ 是迭代次数。

   Adam 算法可以利用一阶矩和二阶矩的信息，实现自适应的学习率调整，使得参数在梯度方向上加速，而在垂直梯度方向上减速，从而避免参数在最优值附近的震荡，加快收敛速度。

> 关于优化器的更多细节：http://cs231n.github.io/neural-networks-3

### 4.2 处理过拟合

1. 过拟合

   - 定义：对训练集拟合得很好，但在验证集表现较差

     神经网络 通常含有大量参数 (数百万甚至数十亿), 容易过拟合

   - 处理策略：参数正则化、早停、随机失活、数据增强

2. 早停

   ![image-20240218152006374](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218152006374.png)

   当发现训练损失逐渐下降，但验证集损失逐渐上升时，及时<font color='red'>停止优化</font>。

3. 随机失活

   - 训练过程

     在训练迭代过程中，以 $p$（通常为0.5）的概率随机舍弃掉每个隐含层神经元（<font color='red'>输出置零</font>）

     ![image-20240218152407979](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218152407979.png)

     这些被置零的输出，将用于在反向传播中计算梯度

   - 优点：

     - 一个隐含层神经元不能依赖于其它存在的神经元，因此可以防止神经元出现复杂的相互协同（co-adaptations）

     - 相当于在合理的时间内训练了<font color='red'>大量不同的网络</font>，并将其结果平均

   - 测试过程

     使用"平均网络（mean network）”，包含所有隐含层神经元

     ![image-20240218152916977](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218152916977.png)

     需要调整神经元输出的权重，用来弥补训练中<font color='blue'>只有一部分被激活</font>的现象

     - p=0.5时，将权重减半
     - p=0.1，在权重上乘1-p，即0.9

     > 实践中，p在低层设得较小，例如0.2，但在高层设得更大，例如0.5
     
     这样得到的结果与在大量网络上做平均得到的结果类似

4. 数据增强

   数据增强（Data Augmentation）是一种用于优化深度学习模型的方法，它可以通过从现有数据生成新的训练数据来扩展原数据集，从而提高模型的泛化能力和防止过拟合。

   数据增强的工具可以对数据进行各种操作和转换，如<font color='blue'>旋转、缩放、裁剪、翻转、调整亮度、对比度、颜色</font>等，以生成新的、多样的、有代表性的样本。

   - 随机翻转

     通常只用左右翻转

     ![image-20240218153939733](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218153939733.png)

   - 随机缩放和裁剪

     ![image-20240218154027438](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218154027438.png)

     - 将测试图像缩放到模型要求的输入大小
     - 剪裁一个区域（通常是中心区域）并输入到模型
     - 剪裁多个并输入到模型，对输出作平均

   - 随机擦除

     ![image-20240218154118949](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218154118949.png)

     测试时可以输入整张图像

### 4.3 批归一化

1. 内部协变量偏移（Internal covariate shift）

   当使用SGD时，不同迭代次数时输入到神经网络的数据不同，<font color='blue'>可能</font>导致某些层输出的分布在不同迭代次数时不同。

   ICS：训练中，深度神经网络中间节点分布的变化。<font color='blue'>可能增加优化难度</font>。

2. 通过归一化来减少ICS

   对每个标量形式的特征单独进行归一化，使其均值为0，方差为1。

   对于d维激活$x=(x_1,…,x_d)$​，作如下归一化
   $$
   \hat x_i=\frac{x_i-E[x_i]}{\sqrt{\text{Var}[x_i]}}
   $$
   保持该层的表达能力
   $$
   y_i=\gamma_i\hat x_i+\beta_i
   $$
   若 $\gamma_i=\sqrt{\text{Var}[x_i]}$ 且 $\beta_i=E[x_i]$ ，恢复到原来的激活值。

3. 批归一化BN（Batch Normalization）

   批归一化（Batch Normalization，BatchNorm）是一种用于优化深度神经网络的方法，它可以通过对每一层的输入数据进行标准化处理，使其<font color='red'>均值为0，方差为1</font>，从而减少每一层输入数据分布的变化，加快网络的收敛速度，提高网络的泛化能力和鲁棒性。

   - 基本思想：

     在每一层的输入数据上进行如下的变换：
     $$
     \tilde{x}_i=\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}} \quad \text{(归一化)}\\
     y_i=\gamma\tilde{x}_i+\beta \quad \text{(尺度变换和偏移)}
     $$
     其中，$x_i$ 是第 $i$ 个神经元的输入，$\mu_B$ 和 $\sigma_B^2$ 是该层输入数据的均值和方差，$\epsilon$ 是一个小常数，用于防止除零错误，$\tilde{x}_i$ 是归一化后的输入，$\gamma$ 和 $\beta$ 是可学习的参数，用于调整数据的尺度和偏移，$y_i$ 是最终的输出。

   - 优点

     - 可以选择较大的初始学习率，加快网络的收敛。
     - 可以减少正则化参数的选择问题，如 Dropout、L2 正则项等。
     - 可以把训练数据彻底打乱，防止每批训练的时候，某一个样本经常被挑选到。
     - 可以缓解梯度消失或梯度爆炸的问题，使得网络可以使用更深的结构和更多的非线性激活函数。

   - 缺点

     - 增加了网络的计算量和内存消耗。
     - 对于小批量的数据，可能会导致不稳定的结果。
     - 对于某些任务，可能会降低网络的表达能力或性能。

4. 其他归一化技巧

   ![image-20240218161027678](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218161027678.png)

   - 批归一化（Batch norm）用于CNN
   - 层归一化（Layer norm）用于RNN
   - 实例归一化（Instance norm）用于图像风格化
   - 群归一化（Group norm）用于CNN处理批较小的情况

### 4.4 超参数选取

1. 超参数

   超参数: 控制算法行为，且不会被算法本身所更新，通常决定了一个模型的<font color='red'>能力</font>

   对于一个深度学习模型, 超参数包括

   - 层数，每层的神经元数目
   - 正则化系数
   - 学习率
   - 参数衰减率（Weight decay rate）
   - 动量项（Momentum rate）

2. 如何选择深度学习模型的架构

   - 熟悉数据集
   - 与之前见过的数据/任务比较
     - 样本数目
     - 图像大小, 视频长度, 输入复杂度…
   - 最好从在类似数据集或任务上表现良好的模型开始

3. 如何选择其它超参数

   > 由Fei-Fei Li & Justin Johnson & Serena Yeung（CS231n 2019，Stanford University）给出的建议

   - 第1步：观察初始损失

     - 确保损失的计算是正确的
     - 将权重衰减设为零

   - 第2步：在一组小样本上过拟合

     - 在一组少量样本的训练集上训练，尝试达到<font color='blue'>100%训练准确率</font>
     - 如果训练损失没有下降，说明是不好的初始化，学习率太小，模型太小
     - 如果训练损失变成Inf或NaN，说明是不好的初始化，学习率太大

   - 第3步：找到使损失下降的学习率

     - 在全部数据上训练模型，并找到使损失值能够快速下降的学习率

       当损失值下降较慢时，将学习率缩小10倍

       使用较小的参数衰减

   - 第4步：粗粒度改变学习率，训练1-5轮

     - 在上一步的基础上，尝试一些比较接近的学习率和衰减率
     - 常用的参数衰减率：1e-4，1e-5，0

   - 第5步：细粒度改变学习率，训练更长时间

     - 使用上一步找到的最好的学习率，并训练更长时间 (10-20 轮)，期间不改变学习率

   - 第6步：观察损失曲线

     - 训练损失通常用<font color='blue'>滑动平均</font>绘制，否则会有很多点聚集在一起

       ![image-20240218161857392](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218161857392.png)

       有问题的损失曲线：

       ![image-20240218162126133](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240218162126133.png)

> 延伸阅读：
>
> - 各种深度学习模型的优化方法：http://cs231n.github.io/neural-networks-3/
> - 关于不同正则化方法的讨论：https://www.cnblogs.com/LXP-
> - Never/p/11566064.html Li，Chen，Hu，Yang，2019
>   Understanding the Disharmony Between Dropout and Batch Normalization by Variance Shift CVPR



