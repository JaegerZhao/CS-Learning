# 机器学习

## 1 基本概念

### 1.1 概述

1. **什么是机器学习 **—— 在某种<font color='blue'>任务</font>上基于<font color='blue'>经验</font>不断<font color='blue'>进步</font>

   T (Task)：需要解决什么<font color='red'>任务</font>

   P(Performance)：任务确定什么<font color='red'>指标</font>

   E(Experience)：通过什么<font color='red'>经验</font>学习进步

2. 归纳学习假设

   任一假设若在<font color='blue'>足够大</font>的<font color='green'>训练样例集</font>中<font color='blue'>很好地逼近</font>目标函数， 它也能在<font color='red'>未见实例</font>中很好地逼近目标函数

3. 通用机器学习系统设计

   - 用于训练的经验——数据、训练过程、特征（训练数据偏差）

   - 到底应该学什么——**目标函数**：正确 vs 可行（<font color='blue'>假设</font>）

   - 应该如何表示——函数类型必须依据<font color='blue'>表达能力</font>仔细选取

   - 具体用什么算法去学习——最小均方误差、梯度下降法

   - 综合设计——<font color='orange'>数据→特征表示→算法→评价</font>

     ![image-20240122215205128](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240122215205128.png)

4. 基本概念

   - **<font color='blue'>实例空间(Instance Space) X</font>**：例：每一天由一些属性描述 天空，空气温度，湿度，风，水，预报

   - **<font color='blue'>假设空间(Hypothesis Space) H</font>**：例：一个假设 if (温度 = 寒冷 AND 湿度 = 高) then 打网球 = 否

   - **<font color='blue'>训练样例空间(Sample Space) D</font>**：正例和负例 (<font color='red'>基于问题设定</font>）<x~1~,c(x~1~)> ,……, <x~m~,c(x~m~)>

   - **<font color='blue'>目标概念(Target Concept) C</font>**：假设$h∈H$，求 $ h(x)=c(x)for\;all\;x∈X $

     全部x的实例空间太大，换成$ h(x)=c(x)for\;all\;x∈D $

5. 有监督和无监督学习

   |          |                        有监督                         |                     无监督                     |
   | -------- | :---------------------------------------------------: | :--------------------------------------------: |
   | 训练样例 | <font color='blue'>(X,Y)对</font>，通常包含人为的努力 | <font color='blue'>仅 X </font>,通常不涉及人力 |
   | 学习目标 |     学习 X 和 Y 的<font color='blue'>关系</font>      |    学习 X 的<font color='blue'>结构</font>     |
   | 效果衡量 |                       损失函数                        |                       无                       |
   | 应用     |    <font color='blue'>预测</font>: X=输入, Y=输出     |     <font color='blue'>分析</font>: X=输入     |

### 1.2 机器学习实验方法与原则

#### 1.2.1 平均指标

1. 回归任务：预测值 $p_i$ 常为连续值，需要衡量与真实值 $y_i$ 之间的误差

   - <font color='red'>平均绝对误差（MAE）</font>
     $$
     MAE=\frac {1} {n}\sum_{i=1}^{n} {|y_i-p_i|}
     $$

   - <font color='red'>均方误差（MSE）</font>：预测误差较大的样本影响更大
     $$
     MSE=\frac {1} {n}\sum_{i=1}^{n} {(y_i-p_i)^2}
     $$

   - <font color='red'>均方根误差（RMSE）</font>：与预测值、标签单位相同
     $$
     RMSE=\sqrt{MSE}=\sqrt{\frac {1} {n}\sum_{i=1}^{n} {(y_i-p_i)^2}}
     $$
     

2. 分类任务：预测值一般为离散的类别，需要判断是否等于真实类别

   - 准确率（Accuracy）
     $$
     Accuracy=\frac {1} {n}\sum_{i=1}^{n} {(y_i=p_i)}
     $$

   - 错误率（Error Rate）
     $$
     Error\,Rate = 1-Accuracy=1-\frac {1} {n}\sum_{i=1}^{n} {(y_i=p_i)}
     $$

     > 以下为针对二分类任务的评价指标
     >
     > ![image-20240122230828785.png](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240122230828785.png)

   - 精度（Precision）:预测为正例的样本中有多少确为正例
     $$
     Precision = \frac{TP}{TP+FP}
     $$

   - 召回率（Recall）：找到的真实正例占所有正例中的比例
     $$
     Recall = \frac{TP}{TP+FN}
     $$

   - 加权调和平均$F_\beta$​：
     $$
     F_\beta=1/[\frac{1}{1+\beta ^2}(\frac{1}{P}+\frac{\beta^2}{R})]\\
     F_1=\frac{2PR}{P+R}
     $$

   - <font color='red'>ROC曲线</font>：表示在不同阈值下模型的真阳性率（TPR）和假阳性率（FPR）之间的关系。

     ![image-20240122232003344](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240122232003344.png)

     - 根据预测值对样本排序
     - 以该样本的预测值为阈值
     - 大于或等于阈值记正例，否则记负例可得到一组结果及评价指标，共有样本数n组结果
     - 假正例率（False Positive Rate，FPR）为横轴
     - 真正例率（True Positive Rate，TPR，也即召回率）为纵轴

   - <font color='red'>AUC（Area Under ROC Curve）</font>：ROC曲线下的面积，越大越好

     - 把测试样例以预测值从大到小排序，其中有n1个真实正例，n0个真实负例
     - 设 $r_i$ 为第 $i$ 个真实负例的秩（排序位置），$S_0=\sum r_i$

     $$
     AUC=\frac{S_0-n_0(n_0+1)/2}{n_0N_1}
     $$

     > ![image-20240122233627200](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240122233627200.png)

3. 特定任务：

   - 个性化推荐：前K项精度（Precision@K）、前K项召回率（Recall@K）、前K项 命中率（Hit@K）等

   - 对话系统：BLEU、ROUGE、METEOR等
   - DCG(Discounted Cumulative Gain)：DCG 是对一个特定位次p的累积增益(Cumulative)

### 1.2.2 训练集、验证集与测试集

1. 训练集：模型可见样本标签，用于训练模型，样本数有限
2. 测试集：用于评估模型在可能出现的未见样本上的表现
3. 验证集：从<font color='blue'>训练集</font>中额外分出的集合，一般用于<font color='blue'>超参数</font>的调整（<font color='red'>防止过拟合</font>）

![image-20240122234843100](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240122234843100.png)

### 1.2.3 随机重复实验

1. 数据随机性：由<font color='blue'>数据集划分</font>带来的评价指标波动
   - （数据足够多时）增多测试样本
   - （数据量有限时）重复多次划分数据集
2. 模型随机性：由<font color='blue'>模型或学习算法</font>本身带来的评价指标波动
   - 更改随机种子重复训练、测试
3. 报告结果：评价指标的均值$\bar X=\frac{1}{n}\sum_{i=1}^{n}X_i$
   - <font color='blue'>样本标准差</font>(个体离散程度，反映了个体对样本均值的代表性)$S=\sqrt{\sum_{i=1}^{n}(X_i-\bar X)^2/(n-1)}$
   - <font color='blue'>标准误差</font>(样本均值的离散程度，反映了样本均值对总体均值的代表性)$SEM=\frac{S}{\sqrt{n}}$

> 注意：保持每次得到的评价指标<font color='blue'>独立同分布(iid)</font>

### 1.2.4 K折交叉验证

​	随机把数据集分成K个<font color='blue'>相等大小的不相交</font>子集，K一般取5、10

![image-20240122235825060](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240122235825060.png)

- 优点：<font color='blue'>数据利用率高</font>，适用于数据较少时
- 缺点：训练集互相有交集，<font color='blue'>每一轮之间并不满足独立同分布</font>
- 增大K，一般情况下：
  - 所估计的模型效果<font color='blue'>偏差（bias）下降</font>
  - 所估计的模型效果<font color='blue'>方差（variance）上升</font>
  - 计算代价上升，更多轮次、训练集更大

### 1.2.4 统计有效性检验

1. 抽样理论基础

   二项分布：描述了在n次次独立的伯努利试验中，成功的次数的离散情况。

   伯努利试验：成功概率: p，失败概率: q =1-p；n次试验中正好得到r次成功的概率为P(r)。
   $$
   P(r)=C_n^rp^r(1-p)^{n-r}=\frac{n!}{r!(n-r)!}p^r(1-p)^{n-r}
   $$
   ![image-20240125204758756](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240125204758756.png)

2. 效果估计

   给定一个假设在<font color='blue'>有限量数据</font>上的准确率，该准确率是否能准确估计在<font color='blue'>其它未见数据</font>上的效果？

   <font color='blue'>n 个随机样本中有 r 个被误分类的概率</font>——<font color='red'>二项分布</font>（样本的错误率=真实的错误率）
   $$
   真实错误率error_D(h)=p,样本错误率error_S(h)=r/n\\
   E[r]=np,E[error_S(h)]=E[r/n]=p=error_D(h)\\
   σ_{error_S(h)}=\frac{σ_r}{n}≈\sqrt{\frac{error_S(h)(1-error_S(h))}{n}}
   $$
   样本期望值=真实期望值；样本方差值≈真实方差值

   - 估计**<font color='blue'>偏差 （Bias）</font>**

     如果 S 是训练集, $error_S (h)$ 是有偏差的，bias指<font color='blue'>样本错误率的期望</font>与<font color='blue'>真实错误率</font>的差值
     $$
     bias=E[error_s(h)]-error_D(h)
     $$
     对于<font color='blue'>无偏估计(bias =0)</font>, h(训练集模型)和 S(测试集)必须<font color='blue'>独立不相关</font>地产生——<font color='red'>不要在训练集上测试！</font>

   - 估计**<font color='blue'>方差 （Varias）</font>**

     即使是S 的无偏估计, $error_S (h)$ 可能仍然和 $error_D (h)$ 不同，例：n=100,r=12;n=25,r=3错误率都为12%，但是方差分别为3.2%,6.5%

     需要选择<font color='red'>无偏</font>的且有<font color='red'>最小方差</font>的估计

3. 置信区间——准确率的估计可能包含多少错误？

   定义：参数p 的N %置信区间是一个以N %的概率包含p 的区间, N% : 置信度

   > 90.0%的置信度 ，年龄：[12, 24]
   >
   > 99.9%的置信度，年龄：[3, 60]

   - 如何得到置信区间?——通过<font color='blue'>正态分布</font>的某个<font color='red'>区间 （面积）</font>来获得

     ![image-20240125213425919](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240125213425919.png)

     均值$μ$有N%的可能性落在区间$y±Z_Nσ$

   - 中心极限定理——当<font color='blue'>样本量足够大</font>时，<font color='blue'>二项分布可以用正态分布来近似</font>。

     经验法则：$n>30, np(1-p)> 5$

     问题设定：

     a. <font color='blue'>独立同分布</font>的随机变量$Y_1,...,Y_n$；

     b. 未知分布，有均值$\mu$和有限方差$\sigma^2$；

     c. 估计均值为$\bar Y=\frac{1}{n}\sum_{i=1}^nY_i$，服从正态分布

     > 若S 包含 n >= 30个样本, 与h独立产生，且每个样本独立采样，则<font color='blue'>真实错误率$error_D$</font>落在以下区间有N% 置信度:
     > $$
     > error_S(h)±z_N\sqrt{\frac{error_S(h)(1-error_S(h))}{n}}
     > $$
     > 

4. 假设检验

   比较两个样本或一个样本和一个常数的均值差异是否显著

   - z检验

     Z检验通常用于大样本（样本容量大于30）或已知总体标准差的情况。Z值的计算方式为：

     $$
     Z = \frac{\bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}}
     $$

     - $\bar{X}$ 是样本均值。
     - $\mu$是总体均值。
     - $\sigma$是总体标准差。
     - $n$ 是样本容量。

     一般用于单次评测，随机变量为<font color='blue'>每个测试样本</font>的对错

   - t检验

     t检验适用于小样本（样本容量小于30）或总体标准差未知的情况。t值的计算方式为：
     $$
     t = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}}
     $$

     - $\bar{X}$ 是样本均值。
     - $\mu$是总体均值。
     - $s$是样本标准差。
     - $n$ 是样本容量。

     一般用于多次评测如重复实验，随机变量为<font color='blue'>每次测试集</font>上的指标

## 2 监督学习

![image-20240117212526879](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240117212526879.png)

### 2.1 决策树

  

### 2.2 回归算法



### 2.3 贝叶斯学习



### 2.4 基于实例的学习



### 2.5 支持向量机（SVM）



## 3 无监督学习



### 3.1 聚类



## 4 集成学习



## 5 深度学习